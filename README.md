Project Description

n this project, we have developed a website that uses our AI models to extract keywords from both the uploaded document and the dataset we use. After both are set, we proceed to extract the keywords, word frequency, and finally the semantic frequency. Once each of these has been evaluated, we compare them with the data in our dataset to determine which are most similar. Based on their similarity, we assign a score for each part—keywords, frequency, and semantics—and then combine them into a final score to list the jobs that are most similar to the uploaded CV.


-------

Set up

First create you own .env file with your google API to use gemenAI.

Install imported libraries

Upload the data set from Kaggel called Linkedin Job Posting.

Then Go to extracting file which will create the JSON you will use

After that run Main.py and that will give you the localhost on which
you can try and test the application

-----

What you need to install:

NLTK, \
GemenAi,\
Flask,\
markdown2, \
collections, \
pandas, \
numpy, \
sklearn


---

Contribution

This is a solo project since my friends didn't have time I choose to join alone
so I guess I can say

Klaus Caka 100%




